{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An initial training pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Andrea\\miniconda3\\envs\\dsi_participant\\lib\\site-packages\\dask\\dataframe\\_pyarrow_compat.py:15: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 11.0.0. Please consider upgrading.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.getenv('SRC_DIR'))\n",
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from glob import glob\n",
    "ft_dir = os.getenv(\"FEATURES_DATA\")\n",
    "ft_glob = glob(ft_dir+'/*.parquet')\n",
    "df = dd.read_parquet(ft_glob).compute().reset_index().dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_file = os.path.join(\n",
    "    os.getenv(\"PRICE_CSV_DATA\"), \n",
    "    'symbols_valid_meta.csv'\n",
    ") #getting the file path\n",
    "cat_df = (pd.read_csv(cat_file)\n",
    "          .rename(columns = {'Symbol': 'ticker'})[['ticker', 'Listing Exchange', 'Market Category']]\n",
    "          ) # only taking these categories from dataframe\n",
    "df = df.merge(cat_df, on = 'ticker', how = 'left') # effectively a left join, all obseravtions from left table, grabbing only matching observations from right-hand table\n",
    "# Joining on 'ticker' \n",
    "# creates extended dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "+ Previously, we produced a features data set.\n",
    "+ Most times, one or more [preprocessing steps](https://scikit-learn.org/stable/modules/preprocessing.html#) steps will be applied to data.\n",
    "+ The most practical way to apply them is by arranging them in `Pipeline` objects, wchich are sequential transformations applied to data. \n",
    "+ It is convenient for us to label these transformations and there is a standard way of doing so.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformations\n",
    "\n",
    "+ Transformations are classes that implement `fit` and `transform` methods.\n",
    "\n",
    "### StandardScaler\n",
    "\n",
    "+ For example, transform a numerical variable by standardizing it.\n",
    "- Standardization is removing the mean value of the feature and scale it by dividing non-constant features by their standard deviation.\n",
    "\n",
    "$$\n",
    "z = \\frac{x-\\mu}{\\sigma}\n",
    "$$\n",
    "\n",
    "\n",
    "+  Using [`StandardScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html), one can do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ticker', 'Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume',\n",
       "       'source', 'Year', 'Close_lag_1', 'Returns', 'Listing Exchange_x',\n",
       "       'Market Category_x', 'Listing Exchange_y', 'Market Category_y',\n",
       "       'Listing Exchange', 'Market Category'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andrea\\AppData\\Local\\Temp\\ipykernel_8256\\3768964069.py:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = (df.assign(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>source</th>\n",
       "      <th>Year</th>\n",
       "      <th>...</th>\n",
       "      <th>Market Category_x</th>\n",
       "      <th>Listing Exchange_y</th>\n",
       "      <th>Market Category_y</th>\n",
       "      <th>Listing Exchange</th>\n",
       "      <th>Market Category</th>\n",
       "      <th>returns</th>\n",
       "      <th>positive_return</th>\n",
       "      <th>hi_lo</th>\n",
       "      <th>op_cl</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACN</td>\n",
       "      <td>2001-07-20</td>\n",
       "      <td>15.05</td>\n",
       "      <td>15.05</td>\n",
       "      <td>14.80</td>\n",
       "      <td>15.01</td>\n",
       "      <td>11.284108</td>\n",
       "      <td>9238500.0</td>\n",
       "      <td>ACN.csv</td>\n",
       "      <td>2001</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>-0.010547</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACN</td>\n",
       "      <td>2001-07-23</td>\n",
       "      <td>15.00</td>\n",
       "      <td>15.01</td>\n",
       "      <td>14.55</td>\n",
       "      <td>15.00</td>\n",
       "      <td>11.276587</td>\n",
       "      <td>7501000.0</td>\n",
       "      <td>ACN.csv</td>\n",
       "      <td>2001</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>-0.000666</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACN</td>\n",
       "      <td>2001-07-24</td>\n",
       "      <td>14.95</td>\n",
       "      <td>14.97</td>\n",
       "      <td>14.70</td>\n",
       "      <td>14.86</td>\n",
       "      <td>11.171341</td>\n",
       "      <td>3537300.0</td>\n",
       "      <td>ACN.csv</td>\n",
       "      <td>2001</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>-0.009333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACN</td>\n",
       "      <td>2001-07-25</td>\n",
       "      <td>14.70</td>\n",
       "      <td>14.95</td>\n",
       "      <td>14.65</td>\n",
       "      <td>14.95</td>\n",
       "      <td>11.238999</td>\n",
       "      <td>4208100.0</td>\n",
       "      <td>ACN.csv</td>\n",
       "      <td>2001</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>0.006057</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACN</td>\n",
       "      <td>2001-07-26</td>\n",
       "      <td>14.95</td>\n",
       "      <td>14.99</td>\n",
       "      <td>14.50</td>\n",
       "      <td>14.50</td>\n",
       "      <td>10.900705</td>\n",
       "      <td>6335300.0</td>\n",
       "      <td>ACN.csv</td>\n",
       "      <td>2001</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>-0.030100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.49</td>\n",
       "      <td>-0.45</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239587</th>\n",
       "      <td>ZIXI</td>\n",
       "      <td>2003-06-25</td>\n",
       "      <td>4.15</td>\n",
       "      <td>4.18</td>\n",
       "      <td>3.99</td>\n",
       "      <td>4.04</td>\n",
       "      <td>4.040000</td>\n",
       "      <td>112100.0</td>\n",
       "      <td>ZIXI.csv</td>\n",
       "      <td>2003</td>\n",
       "      <td>...</td>\n",
       "      <td>Q</td>\n",
       "      <td>Q</td>\n",
       "      <td>Q</td>\n",
       "      <td>Q</td>\n",
       "      <td>Q</td>\n",
       "      <td>-0.049412</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239588</th>\n",
       "      <td>ZIXI</td>\n",
       "      <td>2003-06-26</td>\n",
       "      <td>4.04</td>\n",
       "      <td>4.19</td>\n",
       "      <td>3.86</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>515300.0</td>\n",
       "      <td>ZIXI.csv</td>\n",
       "      <td>2003</td>\n",
       "      <td>...</td>\n",
       "      <td>Q</td>\n",
       "      <td>Q</td>\n",
       "      <td>Q</td>\n",
       "      <td>Q</td>\n",
       "      <td>Q</td>\n",
       "      <td>-0.009901</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239589</th>\n",
       "      <td>ZIXI</td>\n",
       "      <td>2003-06-27</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.05</td>\n",
       "      <td>3.79</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.850000</td>\n",
       "      <td>162400.0</td>\n",
       "      <td>ZIXI.csv</td>\n",
       "      <td>2003</td>\n",
       "      <td>...</td>\n",
       "      <td>Q</td>\n",
       "      <td>Q</td>\n",
       "      <td>Q</td>\n",
       "      <td>Q</td>\n",
       "      <td>Q</td>\n",
       "      <td>-0.037500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.26</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239590</th>\n",
       "      <td>ZIXI</td>\n",
       "      <td>2003-06-30</td>\n",
       "      <td>3.84</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.72</td>\n",
       "      <td>3.77</td>\n",
       "      <td>3.770000</td>\n",
       "      <td>119900.0</td>\n",
       "      <td>ZIXI.csv</td>\n",
       "      <td>2003</td>\n",
       "      <td>...</td>\n",
       "      <td>Q</td>\n",
       "      <td>Q</td>\n",
       "      <td>Q</td>\n",
       "      <td>Q</td>\n",
       "      <td>Q</td>\n",
       "      <td>-0.020779</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.28</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239591</th>\n",
       "      <td>ZIXI</td>\n",
       "      <td>2003-07-01</td>\n",
       "      <td>3.72</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.65</td>\n",
       "      <td>3.78</td>\n",
       "      <td>3.780000</td>\n",
       "      <td>202100.0</td>\n",
       "      <td>ZIXI.csv</td>\n",
       "      <td>2003</td>\n",
       "      <td>...</td>\n",
       "      <td>Q</td>\n",
       "      <td>Q</td>\n",
       "      <td>Q</td>\n",
       "      <td>Q</td>\n",
       "      <td>Q</td>\n",
       "      <td>0.002653</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>239533 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ticker       Date   Open   High    Low  Close  Adj Close     Volume  \\\n",
       "0         ACN 2001-07-20  15.05  15.05  14.80  15.01  11.284108  9238500.0   \n",
       "1         ACN 2001-07-23  15.00  15.01  14.55  15.00  11.276587  7501000.0   \n",
       "2         ACN 2001-07-24  14.95  14.97  14.70  14.86  11.171341  3537300.0   \n",
       "3         ACN 2001-07-25  14.70  14.95  14.65  14.95  11.238999  4208100.0   \n",
       "4         ACN 2001-07-26  14.95  14.99  14.50  14.50  10.900705  6335300.0   \n",
       "...       ...        ...    ...    ...    ...    ...        ...        ...   \n",
       "239587   ZIXI 2003-06-25   4.15   4.18   3.99   4.04   4.040000   112100.0   \n",
       "239588   ZIXI 2003-06-26   4.04   4.19   3.86   4.00   4.000000   515300.0   \n",
       "239589   ZIXI 2003-06-27   4.00   4.05   3.79   3.85   3.850000   162400.0   \n",
       "239590   ZIXI 2003-06-30   3.84   4.00   3.72   3.77   3.770000   119900.0   \n",
       "239591   ZIXI 2003-07-01   3.72   3.85   3.65   3.78   3.780000   202100.0   \n",
       "\n",
       "          source  Year  ...  Market Category_x  Listing Exchange_y  \\\n",
       "0        ACN.csv  2001  ...                                      N   \n",
       "1        ACN.csv  2001  ...                                      N   \n",
       "2        ACN.csv  2001  ...                                      N   \n",
       "3        ACN.csv  2001  ...                                      N   \n",
       "4        ACN.csv  2001  ...                                      N   \n",
       "...          ...   ...  ...                ...                 ...   \n",
       "239587  ZIXI.csv  2003  ...                  Q                   Q   \n",
       "239588  ZIXI.csv  2003  ...                  Q                   Q   \n",
       "239589  ZIXI.csv  2003  ...                  Q                   Q   \n",
       "239590  ZIXI.csv  2003  ...                  Q                   Q   \n",
       "239591  ZIXI.csv  2003  ...                  Q                   Q   \n",
       "\n",
       "       Market Category_y Listing Exchange Market Category   returns  \\\n",
       "0                                       N                 -0.010547   \n",
       "1                                       N                 -0.000666   \n",
       "2                                       N                 -0.009333   \n",
       "3                                       N                  0.006057   \n",
       "4                                       N                 -0.030100   \n",
       "...                  ...              ...             ...       ...   \n",
       "239587                 Q                Q               Q -0.049412   \n",
       "239588                 Q                Q               Q -0.009901   \n",
       "239589                 Q                Q               Q -0.037500   \n",
       "239590                 Q                Q               Q -0.020779   \n",
       "239591                 Q                Q               Q  0.002653   \n",
       "\n",
       "       positive_return hi_lo  op_cl  target  \n",
       "0                  0.0  0.25  -0.04     0.0  \n",
       "1                  0.0  0.46   0.00     0.0  \n",
       "2                  0.0  0.27  -0.09     1.0  \n",
       "3                  1.0  0.30   0.25     0.0  \n",
       "4                  0.0  0.49  -0.45     1.0  \n",
       "...                ...   ...    ...     ...  \n",
       "239587             0.0  0.19  -0.11     0.0  \n",
       "239588             0.0  0.33  -0.04     0.0  \n",
       "239589             0.0  0.26  -0.15     0.0  \n",
       "239590             0.0  0.28  -0.07     1.0  \n",
       "239591             1.0  0.20   0.06     0.0  \n",
       "\n",
       "[239533 rows x 23 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = (df.assign(\n",
    "        returns = lambda x: x['Close']/x['Close_lag_1'] - 1, \n",
    "        positive_return = lambda x: 1.0*(x['returns'] > 0),\n",
    "        hi_lo = lambda x: x['High'] - x['Low'],\n",
    "        op_cl = lambda x: x['Close'] - x['Open'] # creating returns like in assignment 1\n",
    "    ).groupby(['ticker'], group_keys=False).apply(\n",
    "        lambda x: x.assign(target = x['positive_return'].shift(-1)) # create a forward looking variable - create target to check if tomorrow, will the return be positive\n",
    "    )\n",
    "    .reset_index(drop=True) # drop any indices put in\n",
    "    .dropna(subset = ['target']) # drop any missing values from the dataset\n",
    "    )\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns = df[['returns']]\n",
    "# returns = df['returns']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StandardScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a StandardScaler object\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "std_scaler = StandardScaler()\n",
    "\n",
    "\n",
    "# Fit the StandardScaler object with the returns data\n",
    "std_scaler.fit(returns)\n",
    "# std_scaler.fit(returns.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  OneHotEncoder\n",
    "\n",
    "+ Categorical features can be encoded as numerical values using `OneHotEncoder`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>returns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.395330e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-1.479475e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000002e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.205709e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.637541e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-4.040821e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.444178e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.025368e+02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            returns\n",
       "count  2.395330e+05\n",
       "mean  -1.479475e-18\n",
       "std    1.000002e+00\n",
       "min   -1.205709e+00\n",
       "25%   -1.637541e-02\n",
       "50%   -4.040821e-03\n",
       "75%    8.444178e-03\n",
       "max    4.025368e+02"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform the returns data using the fitted scaler\n",
    "\n",
    "scaled_returns_np = std_scaler.transform(returns)\n",
    "# scaled_returns_np = std_scaler.transform(returns.reshape(-1,1))\n",
    "scaled_returns = pd.DataFrame(scaled_returns_np, columns=returns.columns)\n",
    "scaled_returns.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Use [`OneHotEncoder`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) to encode a categorical variable as numerical.\n",
    "+ Important parameters:\n",
    "\n",
    "    - `categories` allows you to specify the categories to work with.\n",
    "    - `drop`: we can drop the `'first'` value (dummy encoding) or `'if_binary'`, a convenience setting for binary values.\n",
    "    - `handle_unknown` allows three options, `'error'`, `'ignore'`, and `'infrequent_if_exist'`, depending on what we want to do with new values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Listing Exchange'>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['Listing Exchange'].value_counts().plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneHotEncoder(drop=&#x27;first&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(drop=&#x27;first&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "OneHotEncoder(drop='first')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "onehot = OneHotEncoder(drop='first') # drop since values are binary, cuts 4 cols down to 3 (dummy transformation)\n",
    "onehot.fit(df[['Listing Exchange']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listing_enc = onehot.transform(df[['Listing Exchange']])\n",
    "listing_enc.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines\n",
    "\n",
    "+ It is impractical and costly to manipulate data \"by hand\". \n",
    "+ To manage data preprocessing steps within the cross-validation process use `Pipeline` objects.\n",
    "+ A [`Pipeline`](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) object allows us to sequentially apply transformation steps and, if required, a predictor.\n",
    "+ `Pipeline` objects compose transforms, i.e., classes that implement `transform` and `fit` methods.\n",
    "+ The purpose of `Pipeline` objects is to ensemble transforms and predictors to be used in cross-validation.\n",
    "+ A `Pipeline` is defined by a list of tuples.\n",
    "+ Each tuple is composed of `(\"name\", <ColumnTransformer>)`, the name of the step and the `<ColumnTransformer>` function of our chosing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, log_loss, cohen_kappa_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;onehot&#x27;, OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)),\n",
       "                (&#x27;knn&#x27;,\n",
       "                 DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=3))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;onehot&#x27;, OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)),\n",
       "                (&#x27;knn&#x27;,\n",
       "                 DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=3))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=3)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore')),\n",
       "                ('knn',\n",
       "                 DecisionTreeClassifier(criterion='entropy', max_depth=3))])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe1 = Pipeline(\n",
    "    [\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore')),\n",
    "        ('knn', DecisionTreeClassifier(criterion = 'entropy', max_depth=3))\n",
    "\n",
    "    ]\n",
    ")\n",
    "pipe1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;onehot&#x27;, OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)),\n",
       "                (&#x27;knn&#x27;,\n",
       "                 DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=3))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;onehot&#x27;, OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)),\n",
       "                (&#x27;knn&#x27;,\n",
       "                 DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=3))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=3)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore')),\n",
       "                ('knn',\n",
       "                 DecisionTreeClassifier(criterion='entropy', max_depth=3))])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X0 = df[['Listing Exchange', 'Market Category']] # taking two categorical variables - will tomorrow bring a positive return\n",
    "Y0 = df['target']\n",
    "X0_train, X0_test, Y0_train, Y0_test = train_test_split(X0, Y0, test_size=0.2, random_state=42) # create train/test samples, with 20% reserved for testing\n",
    "\n",
    "pipe1.fit(X0_train, Y0_train) # fit the pipeline, single command applied to all elements in the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_train = pipe1.predict(X0_train) # get training preds\n",
    "Y_pred_test = pipe1.predict(X0_test) # get testing preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_poba_train = pipe1.predict_proba(X0_train) #standard output of classifiers in scikit learn - score (not a calibrated probability)\n",
    "Y_proba_test = pipe1.predict_proba(X0_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy_score_train': 0.5436214292423783,\n",
       " 'accuracy_score_test': 0.5410274072682489,\n",
       " 'cohen_kappa_train': 0.0,\n",
       " 'cohen_kappa_test': 0.0,\n",
       " 'log_loss_train': 0.6885455693418755,\n",
       " 'log_loss_test': 0.6890481947278746,\n",
       " 'f1_score_train': 0.0,\n",
       " 'f1_score_test': 0.0}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = { #opening a dictionary\n",
    "    'accuracy_score_train': accuracy_score(Y0_train, Y_pred_train), # (if evaluing against train set, use pred for train set, etc.)\n",
    "    'accuracy_score_test': accuracy_score(Y0_test, Y_pred_test),\n",
    "    'cohen_kappa_train': cohen_kappa_score(Y0_train, Y_pred_train),\n",
    "    'cohen_kappa_test': cohen_kappa_score(Y0_test, Y_pred_test),\n",
    "    'log_loss_train': log_loss(Y0_train, Y_poba_train),\n",
    "    'log_loss_test': log_loss(Y0_test, Y_proba_test),\n",
    "    'f1_score_train': f1_score(Y0_train, Y_pred_train),\n",
    "    'f1_score_test': f1_score(Y0_test, Y_pred_test)\n",
    "}\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ The model does not show great performance, but the pipeline shows results. \n",
    "+ Below, we expand the pipeline to include more variables, and further we will work with more robust model selection pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ColumnTransformer\n",
    "\n",
    "+ Use [`ColumnTransformer`](https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html) to apply transformers to specific columns of a DataFrame.\n",
    "+ In this case, we will scale numeric variables and apply one-hot encoding to categorical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('numeric_transfomer', StandardScaler(), ['returns', 'Volume', 'op_cl', 'hi_lo'] ),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='infrequent_if_exist'), ['Listing Exchange', 'Market Category']), \n",
    "    ], remainder='drop'\n",
    ")\n",
    "\n",
    "pipe = Pipeline(\n",
    "    [\n",
    "        ('preproc', transformer), \n",
    "        ('decisiontree', DecisionTreeClassifier(criterion = 'entropy', max_depth=3))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection\n",
    "\n",
    "The model selection process is an iterative process in which :\n",
    "\n",
    "+ Select schema and load data.\n",
    "+ Define a pipeline and its (hyper) parameters.\n",
    "\n",
    "    - Use ColumnTransformers to transform numeric and cateogrical variables.\n",
    "    - Hyperparameters can be defined independently of code. \n",
    "\n",
    "+ Implement a splitting strategy. \n",
    "\n",
    "    - Use [cross_validate]() to select several metrics and operational details.\n",
    "\n",
    "+ Measure performance.\n",
    "\n",
    "    - [Select metrics](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics)\n",
    "\n",
    "+ Repeat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training, Validation, Testing Split\n",
    "\n",
    "+ The first spliting strategy is to use a training, validation, and test set.\n",
    "+ Training set will be used to fit the model.\n",
    "+ Validation set is used to evaluate hyperparameter choice.\n",
    "+ Testing set is used to evaluate performance on data the model has not yet seen.\n",
    "+ In this case we want to compare two models: \n",
    "\n",
    "    - Decision Tree with 3 minumum samples per leaf.\n",
    "    - Decision Tree with 10 minimum samples per leaf.\n",
    "\n",
    "![](./images/03b_train_validate_test.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting parameters in pipeline steps\n",
    "\n",
    "+ One can obtain the parameters of a pipeline with `pipe.get_params()`.\n",
    "+ We can set any parameter of a pipeline with `pipe.set_parames(**kwargs)`. \n",
    "+ The input `**kwargs` is a dictionary of the params to be modified. Params of the steps are labeled with the name of the step followed by `__` and the name of the parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ There are a few steps that we will repeat: \n",
    "\n",
    "    - Fit the candidate model on training data.\n",
    "    - Predict on training and test data.\n",
    "    - Compute training and test performance metrics.\n",
    "    - Return.\n",
    "\n",
    "+ We encapsulate this procedure in a function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(clf, X_train, Y_train, X_test, Y_test):\n",
    "    clf.fit(X_train, Y_train)\n",
    "    Y_pred_train = clf.predict(X_train)\n",
    "    Y_pred_test = clf.predict(X_test)\n",
    "    Y_proba_train = clf.predict_proba(X_train)\n",
    "    Y_proba_test = clf.predict_proba(X_test)\n",
    "    performance_metrics = {\n",
    "        'log_loss_train': log_loss(Y_train, Y_proba_train),\n",
    "        'log_loss_test': log_loss(Y_test, Y_proba_test),\n",
    "        'cohen_kappa_train': cohen_kappa_score(Y_train, Y_pred_train),\n",
    "        'cohen_kappa_test': cohen_kappa_score(Y_test, Y_pred_test),\n",
    "        'f1_score_train': f1_score(Y_train, Y_pred_train),\n",
    "        'f1_score_test': f1_score(Y_test, Y_pred_test),\n",
    "        'accuracy_score_train': accuracy_score(Y_train, Y_pred_train),\n",
    "        'accuracy_score_test': accuracy_score(Y_test, Y_pred_test),\n",
    "    }\n",
    "    return performance_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schema\n",
    "X = df[['returns', 'op_cl', 'hi_lo', 'Volume', 'Listing Exchange', 'Market Category']]\n",
    "Y = df['target']\n",
    "\n",
    "# Split the data\n",
    "X_rest, X_test, Y_rest, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "X_train, X_validate, Y_train,  Y_validate = train_test_split(X_rest, Y_rest, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'log_loss_train': 0.6789752594183754,\n",
       " 'log_loss_test': 0.6796638669864612,\n",
       " 'cohen_kappa_train': 0.0,\n",
       " 'cohen_kappa_test': 0.0,\n",
       " 'f1_score_train': 0.0,\n",
       " 'f1_score_test': 0.0,\n",
       " 'accuracy_score_train': 0.5439399869536856,\n",
       " 'accuracy_score_test': 0.5423472316443145}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate hyperparameter configuration 2\n",
    "pipe_d3 = pipe.set_params(**{'decisiontree__max_depth': 3}) # in this classifier, we know the param decisiontree__max_depth exists and we're setting it to 3\n",
    "res_d3 = evaluate_model(pipe_d3, X_train, Y_train, X_validate, Y_validate)\n",
    "res_d3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'log_loss_train': 0.6316582282215347,\n",
       " 'log_loss_test': 1.5527246685221383,\n",
       " 'cohen_kappa_train': 0.1569130595300522,\n",
       " 'cohen_kappa_test': 0.05664342390392352,\n",
       " 'f1_score_train': 0.5031531602371554,\n",
       " 'f1_score_test': 0.4448140593127256,\n",
       " 'accuracy_score_train': 0.5878277886497064,\n",
       " 'accuracy_score_test': 0.5384073474925638}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate hyperparameter configuration 2\n",
    "pipe_d15 = pipe.set_params(**{'decisiontree__max_depth':15}) # max_depth we're allow the param to go\n",
    "res_d15 = evaluate_model(pipe_d15, X_train, Y_train, X_validate, Y_validate)\n",
    "res_d15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation\n",
    "\n",
    "+ Cross-validation is a resampling method.\n",
    "+ It is an iterative method applied to training data.\n",
    "+ Training data is divided into folds.\n",
    "+ Each fold is used once as a validation set and the rest of the folds are used for training.\n",
    "+ Test data is used for final evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From [Scikit's Documentation ](https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation-evaluating-estimator-performance), the diagram below shows the data divisions and folds during the cross-validation process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/03b_grid_search_cross_validation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two functions that can be used for [calculating cross-validation performance scores](https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation-evaluating-estimator-performance): `cross_val_score()` and `cross_validate()`. The first function, [`cross_val_score()`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score), is a convenience function to get quick perfromance calculations. We will discuss `cross_validate()` as it offers advantages over `cross_val_score()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining metrics\n",
    "\n",
    "+ Use [`cross_validate`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate) to measure one or more performance metrics and operational details.\n",
    "+ There are two advantages of using this function. From [Scikit's documentation](https://scikit-learn.org/stable/modules/cross_validation.html#the-cross-validate-function-and-multiple-metric-evaluation):\n",
    "\n",
    ">- It allows specifying multiple metrics for evaluation.\n",
    ">- It returns a dict containing fit-times, score-times (and optionally training scores, fitted estimators, train-test split indices) in addition to the test score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "scoring = ['accuracy', 'f1', 'precision', 'recall', 'roc_auc', 'neg_log_loss', 'neg_brier_score']\n",
    "d3_dict = cross_validate(pipe_d3, X, Y, cv=5, scoring = scoring, return_train_score = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In DataFrame form:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_roc_auc</th>\n",
       "      <th>train_roc_auc</th>\n",
       "      <th>test_neg_log_loss</th>\n",
       "      <th>train_neg_log_loss</th>\n",
       "      <th>test_neg_brier_score</th>\n",
       "      <th>train_neg_brier_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.702392</td>\n",
       "      <td>0.393774</td>\n",
       "      <td>0.541779</td>\n",
       "      <td>0.583579</td>\n",
       "      <td>0.443662</td>\n",
       "      <td>0.502187</td>\n",
       "      <td>0.498179</td>\n",
       "      <td>0.553319</td>\n",
       "      <td>0.399899</td>\n",
       "      <td>0.459705</td>\n",
       "      <td>0.549645</td>\n",
       "      <td>0.631454</td>\n",
       "      <td>-1.692908</td>\n",
       "      <td>-0.637717</td>\n",
       "      <td>-0.259198</td>\n",
       "      <td>-0.227677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.056414</td>\n",
       "      <td>0.601790</td>\n",
       "      <td>0.523556</td>\n",
       "      <td>0.589654</td>\n",
       "      <td>0.345707</td>\n",
       "      <td>0.507074</td>\n",
       "      <td>0.463989</td>\n",
       "      <td>0.561970</td>\n",
       "      <td>0.275481</td>\n",
       "      <td>0.461949</td>\n",
       "      <td>0.517032</td>\n",
       "      <td>0.641724</td>\n",
       "      <td>-2.327348</td>\n",
       "      <td>-0.629078</td>\n",
       "      <td>-0.277468</td>\n",
       "      <td>-0.224506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.898541</td>\n",
       "      <td>0.848601</td>\n",
       "      <td>0.507546</td>\n",
       "      <td>0.596093</td>\n",
       "      <td>0.481836</td>\n",
       "      <td>0.498019</td>\n",
       "      <td>0.463982</td>\n",
       "      <td>0.576192</td>\n",
       "      <td>0.501119</td>\n",
       "      <td>0.438523</td>\n",
       "      <td>0.503346</td>\n",
       "      <td>0.650408</td>\n",
       "      <td>-1.822060</td>\n",
       "      <td>-0.626207</td>\n",
       "      <td>-0.271976</td>\n",
       "      <td>-0.223162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.873482</td>\n",
       "      <td>0.751287</td>\n",
       "      <td>0.511752</td>\n",
       "      <td>0.590997</td>\n",
       "      <td>0.412193</td>\n",
       "      <td>0.491567</td>\n",
       "      <td>0.458054</td>\n",
       "      <td>0.568906</td>\n",
       "      <td>0.374680</td>\n",
       "      <td>0.432739</td>\n",
       "      <td>0.503064</td>\n",
       "      <td>0.643518</td>\n",
       "      <td>-2.606229</td>\n",
       "      <td>-0.630048</td>\n",
       "      <td>-0.293478</td>\n",
       "      <td>-0.224587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.167272</td>\n",
       "      <td>0.494532</td>\n",
       "      <td>0.541122</td>\n",
       "      <td>0.584458</td>\n",
       "      <td>0.378537</td>\n",
       "      <td>0.482831</td>\n",
       "      <td>0.496478</td>\n",
       "      <td>0.559661</td>\n",
       "      <td>0.305875</td>\n",
       "      <td>0.424549</td>\n",
       "      <td>0.537684</td>\n",
       "      <td>0.630734</td>\n",
       "      <td>-1.572014</td>\n",
       "      <td>-0.638192</td>\n",
       "      <td>-0.262968</td>\n",
       "      <td>-0.227936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_accuracy  train_accuracy   test_f1  train_f1  \\\n",
       "0  4.702392    0.393774       0.541779        0.583579  0.443662  0.502187   \n",
       "1  4.056414    0.601790       0.523556        0.589654  0.345707  0.507074   \n",
       "2  7.898541    0.848601       0.507546        0.596093  0.481836  0.498019   \n",
       "3  3.873482    0.751287       0.511752        0.590997  0.412193  0.491567   \n",
       "4  5.167272    0.494532       0.541122        0.584458  0.378537  0.482831   \n",
       "\n",
       "   test_precision  train_precision  test_recall  train_recall  test_roc_auc  \\\n",
       "0        0.498179         0.553319     0.399899      0.459705      0.549645   \n",
       "1        0.463989         0.561970     0.275481      0.461949      0.517032   \n",
       "2        0.463982         0.576192     0.501119      0.438523      0.503346   \n",
       "3        0.458054         0.568906     0.374680      0.432739      0.503064   \n",
       "4        0.496478         0.559661     0.305875      0.424549      0.537684   \n",
       "\n",
       "   train_roc_auc  test_neg_log_loss  train_neg_log_loss  test_neg_brier_score  \\\n",
       "0       0.631454          -1.692908           -0.637717             -0.259198   \n",
       "1       0.641724          -2.327348           -0.629078             -0.277468   \n",
       "2       0.650408          -1.822060           -0.626207             -0.271976   \n",
       "3       0.643518          -2.606229           -0.630048             -0.293478   \n",
       "4       0.630734          -1.572014           -0.638192             -0.262968   \n",
       "\n",
       "   train_neg_brier_score  \n",
       "0              -0.227677  \n",
       "1              -0.224506  \n",
       "2              -0.223162  \n",
       "3              -0.224587  \n",
       "4              -0.227936  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(d3_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_roc_auc</th>\n",
       "      <th>train_roc_auc</th>\n",
       "      <th>test_neg_log_loss</th>\n",
       "      <th>train_neg_log_loss</th>\n",
       "      <th>test_neg_brier_score</th>\n",
       "      <th>train_neg_brier_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.525011</td>\n",
       "      <td>0.721823</td>\n",
       "      <td>0.541821</td>\n",
       "      <td>0.583569</td>\n",
       "      <td>0.443543</td>\n",
       "      <td>0.502087</td>\n",
       "      <td>0.498234</td>\n",
       "      <td>0.553326</td>\n",
       "      <td>0.399671</td>\n",
       "      <td>0.459534</td>\n",
       "      <td>0.549746</td>\n",
       "      <td>0.631423</td>\n",
       "      <td>-1.702265</td>\n",
       "      <td>-0.637732</td>\n",
       "      <td>-0.259307</td>\n",
       "      <td>-0.227686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.543694</td>\n",
       "      <td>0.377298</td>\n",
       "      <td>0.523347</td>\n",
       "      <td>0.589779</td>\n",
       "      <td>0.345158</td>\n",
       "      <td>0.507212</td>\n",
       "      <td>0.463565</td>\n",
       "      <td>0.562140</td>\n",
       "      <td>0.274933</td>\n",
       "      <td>0.462063</td>\n",
       "      <td>0.516761</td>\n",
       "      <td>0.641918</td>\n",
       "      <td>-2.351774</td>\n",
       "      <td>-0.628898</td>\n",
       "      <td>-0.277785</td>\n",
       "      <td>-0.224449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.951679</td>\n",
       "      <td>0.884638</td>\n",
       "      <td>0.507254</td>\n",
       "      <td>0.596177</td>\n",
       "      <td>0.481278</td>\n",
       "      <td>0.500951</td>\n",
       "      <td>0.463652</td>\n",
       "      <td>0.575324</td>\n",
       "      <td>0.500297</td>\n",
       "      <td>0.443606</td>\n",
       "      <td>0.502792</td>\n",
       "      <td>0.650646</td>\n",
       "      <td>-1.837602</td>\n",
       "      <td>-0.626204</td>\n",
       "      <td>-0.272300</td>\n",
       "      <td>-0.223153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.737413</td>\n",
       "      <td>0.444048</td>\n",
       "      <td>0.511731</td>\n",
       "      <td>0.590955</td>\n",
       "      <td>0.412773</td>\n",
       "      <td>0.491271</td>\n",
       "      <td>0.458122</td>\n",
       "      <td>0.568922</td>\n",
       "      <td>0.375594</td>\n",
       "      <td>0.432270</td>\n",
       "      <td>0.502922</td>\n",
       "      <td>0.643450</td>\n",
       "      <td>-2.605691</td>\n",
       "      <td>-0.630051</td>\n",
       "      <td>-0.293549</td>\n",
       "      <td>-0.224594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.565167</td>\n",
       "      <td>0.544295</td>\n",
       "      <td>0.540809</td>\n",
       "      <td>0.584531</td>\n",
       "      <td>0.378131</td>\n",
       "      <td>0.482875</td>\n",
       "      <td>0.495922</td>\n",
       "      <td>0.559779</td>\n",
       "      <td>0.305556</td>\n",
       "      <td>0.424549</td>\n",
       "      <td>0.537125</td>\n",
       "      <td>0.630865</td>\n",
       "      <td>-1.574822</td>\n",
       "      <td>-0.638141</td>\n",
       "      <td>-0.263211</td>\n",
       "      <td>-0.227909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_accuracy  train_accuracy   test_f1  train_f1  \\\n",
       "0  4.525011    0.721823       0.541821        0.583569  0.443543  0.502087   \n",
       "1  4.543694    0.377298       0.523347        0.589779  0.345158  0.507212   \n",
       "2  5.951679    0.884638       0.507254        0.596177  0.481278  0.500951   \n",
       "3  4.737413    0.444048       0.511731        0.590955  0.412773  0.491271   \n",
       "4  4.565167    0.544295       0.540809        0.584531  0.378131  0.482875   \n",
       "\n",
       "   test_precision  train_precision  test_recall  train_recall  test_roc_auc  \\\n",
       "0        0.498234         0.553326     0.399671      0.459534      0.549746   \n",
       "1        0.463565         0.562140     0.274933      0.462063      0.516761   \n",
       "2        0.463652         0.575324     0.500297      0.443606      0.502792   \n",
       "3        0.458122         0.568922     0.375594      0.432270      0.502922   \n",
       "4        0.495922         0.559779     0.305556      0.424549      0.537125   \n",
       "\n",
       "   train_roc_auc  test_neg_log_loss  train_neg_log_loss  test_neg_brier_score  \\\n",
       "0       0.631423          -1.702265           -0.637732             -0.259307   \n",
       "1       0.641918          -2.351774           -0.628898             -0.277785   \n",
       "2       0.650646          -1.837602           -0.626204             -0.272300   \n",
       "3       0.643450          -2.605691           -0.630051             -0.293549   \n",
       "4       0.630865          -1.574822           -0.638141             -0.263211   \n",
       "\n",
       "   train_neg_brier_score  \n",
       "0              -0.227686  \n",
       "1              -0.224449  \n",
       "2              -0.223153  \n",
       "3              -0.224594  \n",
       "4              -0.227909  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d15_dict = cross_validate(pipe_d15, X, Y, cv=5, scoring = scoring, return_train_score = True) # asked for 5 folds\n",
    "pd.DataFrame(d15_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About Performance\n",
    "\n",
    "+ Notice that in order to acquire information about our model and continue development, we are spending resources: time, electricity, equipment use, etc. As well, we are generating data and binary objects that implement our models (fitted `Pipeline` objects, for example).\n",
    "+ For certain applications, operating performance (latency or `'score_time'`) may be as important or more important than predictive performance metrics. \n",
    "+ Every experiment throws important information and we can log them, as well as run them systematically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time                 4.864593\n",
       "score_time               0.594421\n",
       "test_accuracy            0.524992\n",
       "train_accuracy           0.589002\n",
       "test_f1                  0.412177\n",
       "train_f1                 0.496879\n",
       "test_precision           0.475899\n",
       "train_precision          0.563898\n",
       "test_recall              0.371210\n",
       "train_recall             0.444404\n",
       "test_roc_auc             0.521869\n",
       "train_roc_auc            0.639660\n",
       "test_neg_log_loss       -2.014431\n",
       "train_neg_log_loss      -0.632205\n",
       "test_neg_brier_score    -0.273230\n",
       "train_neg_brier_score   -0.225558\n",
       "dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(d15_dict).mean() # calculate the average, use this to evaluate models and make our decisions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsi_participant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
